{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.6.0+cu124\n",
      "CUDA Available: True\n",
      "CUDA Device Name: NVIDIA GeForce RTX 4090\n",
      "CUDA Capability: (8, 9)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Installs and Imports\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, Blip2Processor, Blip2Model, Blip2Config, Blip2VisionModel, Blip2QFormerModel, BlipImageProcessor\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "# print(f\"Transformers Version: {transformers.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Capability: {torch.cuda.get_device_capability(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ViBLIP Q-Former Training Configuration ---\n",
      "Device: cuda\n",
      "Base BLIP-2 Model: Salesforce/blip2-flan-t5-xl\n",
      "Text Tokenizer: vinai/phobert-base\n",
      "Batch Size: 32\n",
      "Use AMP: True\n",
      "Epochs: 1\n",
      "Q-Former LR: 0.0001\n",
      "Early Stop Patience: 3\n",
      "Output Path: ./ViBLIP_QFormer_Trained\n",
      "Data Path (JSONs): /home/researcher/huypq69/TuningModels/data/LANDMARK-IN-VIETNAM\n",
      "Image Base Path: /home/researcher/huypq69/TuningModels/data/LANDMARK-IN-VIETNAM\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Configuration Class (CFG) - Updated with Early Stopping\n",
    "\n",
    "class CFG:\n",
    "    # --- Paths ---\n",
    "    data_path = \"./data/LANDMARK-IN-VIETNAM/\"  # Adjust to where train.json, dev.json, test.json are located\n",
    "    image_path = \"./data/LANDMARK-IN-VIETNAM/\"  # Base path for resolving image paths in JSON\n",
    "    model_path = \"./ViBLIP_QFormer_Trained\"  # Output directory for saved models\n",
    "\n",
    "    # --- Model Selection ---\n",
    "    blip2_model_name = \"Salesforce/blip2-flan-t5-xl\"  # Uses ViT-B by default\n",
    "    text_tokenizer_name = \"vinai/phobert-base\"  # Vietnamese tokenizer\n",
    "\n",
    "    # --- Training Parameters ---\n",
    "    seed = 42\n",
    "    batch_size = 32  # Reduced for RTX 4090 stability\n",
    "    num_workers = 8  # Adjusted for typical CPU\n",
    "    qformer_lr = 1e-4\n",
    "    weight_decay = 0.05\n",
    "    patience = 2  # For LR scheduler\n",
    "    factor = 0.8\n",
    "    epochs = 1\n",
    "    early_stop_patience = 3  # Stop if no improvement for 3 epochs\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    use_amp = True\n",
    "\n",
    "    # --- Image/Text Parameters ---\n",
    "    image_size = 224\n",
    "    max_length = 77\n",
    "\n",
    "    # --- Loss/Saving Parameters ---\n",
    "    temperature = 0.07\n",
    "    save_best_only = True\n",
    "    metric_to_track = \"val_itc_acc\"\n",
    "    mode = \"max\"\n",
    "\n",
    "config = CFG()\n",
    "os.makedirs(config.model_path, exist_ok=True)\n",
    "print(f\"--- ViBLIP Q-Former Training Configuration ---\")\n",
    "print(f\"Device: {config.device}\")\n",
    "print(f\"Base BLIP-2 Model: {config.blip2_model_name}\")\n",
    "print(f\"Text Tokenizer: {config.text_tokenizer_name}\")\n",
    "print(f\"Batch Size: {config.batch_size}\")\n",
    "print(f\"Use AMP: {config.use_amp}\")\n",
    "print(f\"Epochs: {config.epochs}\")\n",
    "print(f\"Q-Former LR: {config.qformer_lr}\")\n",
    "print(f\"Early Stop Patience: {config.early_stop_patience}\")\n",
    "print(f\"Output Path: {config.model_path}\")\n",
    "print(f\"Data Path (JSONs): {os.path.abspath(config.data_path)}\")\n",
    "print(f\"Image Base Path: {os.path.abspath(config.image_path)}\")\n",
    "print(f\"---------------------------------------------\\n\")\n",
    "if config.data_path == \".\" and config.image_path == \".\":\n",
    "    print(\"WARNING: Using current directory for data and image paths. Ensure JSON files and images are present.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Seeding for Reproducibility\n",
    "\n",
    "def set_seed(seed=config.seed):\n",
    "    print(f\"Setting seed: {seed}\")\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric utilities defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Metric Calculation Utilities\n",
    "\n",
    "class AvgMeter:\n",
    "    def __init__(self, name=\"Metric\"):\n",
    "        self.name = name\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        self.avg = 0\n",
    "\n",
    "    def update(self, val, count=1):\n",
    "        if torch.is_tensor(val): val = val.item()\n",
    "        if isinstance(val, (int, float)):\n",
    "            self.sum += val * count\n",
    "            self.count += count\n",
    "            self.avg = self.sum / self.count if self.count != 0 else 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.name}: {self.avg:.4f}\"\n",
    "\n",
    "def compute_recall_at_k(similarity_matrix, k, dim):\n",
    "    n = similarity_matrix.shape[1-dim]\n",
    "    if n == 0 or k <= 0: return 0.0\n",
    "    effective_k = min(k, n)\n",
    "    correct_count = 0\n",
    "    top_k_indices = torch.topk(similarity_matrix, effective_k, dim=dim).indices\n",
    "    ground_truth = torch.arange(n, device=similarity_matrix.device)\n",
    "\n",
    "    if dim == 0: # I2T\n",
    "        for img_idx in range(n):\n",
    "            if ground_truth[img_idx] in top_k_indices[:, img_idx]: correct_count += 1\n",
    "    elif dim == 1: # T2I\n",
    "        for txt_idx in range(n):\n",
    "            if ground_truth[txt_idx] in top_k_indices[txt_idx, :]: correct_count += 1\n",
    "    else: raise ValueError(\"dim must be 0 or 1\")\n",
    "    return correct_count / n\n",
    "\n",
    "def compute_metrics(image_embeddings, text_embeddings):\n",
    "    image_embeddings = image_embeddings.float()\n",
    "    text_embeddings = text_embeddings.float()\n",
    "\n",
    "    sim_matrix = text_embeddings @ image_embeddings.T\n",
    "    n = sim_matrix.shape[0]\n",
    "    default_metrics = {\n",
    "        \"i2t_acc\": 0.0, \"t2i_acc\": 0.0, \"avg_acc\": 0.0,\n",
    "        \"avg_cosine_sim\": 0.0,\n",
    "        \"i2t_recall\": {\"R@1\": 0.0, \"R@5\": 0.0, \"R@10\": 0.0},\n",
    "        \"t2i_recall\": {\"R@1\": 0.0, \"R@5\": 0.0, \"R@10\": 0.0}\n",
    "    }\n",
    "    if n == 0: return default_metrics\n",
    "\n",
    "    try:\n",
    "        ground_truth = torch.arange(n, device=sim_matrix.device)\n",
    "        i2t_preds = torch.argmax(sim_matrix, dim=0)\n",
    "        t2i_preds = torch.argmax(sim_matrix, dim=1)\n",
    "        i2t_acc = (i2t_preds == ground_truth).float().mean().item()\n",
    "        t2i_acc = (t2i_preds == ground_truth).float().mean().item()\n",
    "        avg_acc = (i2t_acc + t2i_acc) / 2\n",
    "        diag_len = min(sim_matrix.shape[0], sim_matrix.shape[1])\n",
    "        avg_cosine_sim = torch.diagonal(sim_matrix[:diag_len, :diag_len]).mean().item()\n",
    "\n",
    "        i2t_recall = {}\n",
    "        t2i_recall = {}\n",
    "        for k in [1, 5, 10]:\n",
    "            k_str = f\"R@{k}\"\n",
    "            i2t_recall[k_str] = compute_recall_at_k(sim_matrix, k, dim=0)\n",
    "            t2i_recall[k_str] = compute_recall_at_k(sim_matrix, k, dim=1)\n",
    "\n",
    "        return {\n",
    "            \"i2t_acc\": i2t_acc, \"t2i_acc\": t2i_acc, \"avg_acc\": avg_acc,\n",
    "            \"avg_cosine_sim\": avg_cosine_sim,\n",
    "            \"i2t_recall\": i2t_recall, \"t2i_recall\": t2i_recall\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error during metric calculation: {e}\")\n",
    "        print(f\"Shapes: ImgEmb={image_embeddings.shape}, TxtEmb={text_embeddings.shape}, SimMtx={sim_matrix.shape}\")\n",
    "        return default_metrics\n",
    "\n",
    "print(\"Metric utilities defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageCaptionDataset class defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Dataset Class Definition\n",
    "\n",
    "class ImageCaptionDataset(Dataset):\n",
    "    def __init__(self, json_path, image_base_path, tokenizer, image_processor, max_length):\n",
    "        super().__init__()\n",
    "        print(f\"Loading data from: {os.path.abspath(json_path)}\")\n",
    "        self.data = []\n",
    "        try:\n",
    "            with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                self.data = json.load(f)\n",
    "            print(f\"Loaded {len(self.data)} samples from {os.path.basename(json_path)}.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"ERROR: JSON file not found at {json_path}\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error loading JSON: {e}\")\n",
    "\n",
    "        self.image_base_path = image_base_path\n",
    "        self.tokenizer = tokenizer\n",
    "        self.image_processor = image_processor\n",
    "        self.max_length = max_length\n",
    "        if not os.path.isdir(self.image_base_path):\n",
    "            print(f\"WARNING: Image base path does not exist: {os.path.abspath(self.image_base_path)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.data): raise IndexError(\"Index out of bounds\")\n",
    "        item = self.data[idx]\n",
    "        relative_image_path = item.get('image_path')\n",
    "        caption = item.get('caption', '')\n",
    "        image = None\n",
    "\n",
    "        if relative_image_path:\n",
    "            image_path = os.path.normpath(os.path.join(self.image_base_path, relative_image_path))\n",
    "            try:\n",
    "                img_pil = Image.open(image_path).convert('RGB')\n",
    "                image_processed = self.image_processor(images=img_pil, return_tensors=\"pt\")\n",
    "                image = image_processed['pixel_values'].squeeze(0)\n",
    "            except FileNotFoundError:\n",
    "                image = None\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {image_path}: {e}\")\n",
    "                image = None\n",
    "\n",
    "        if image is None:\n",
    "            c = 3\n",
    "            h = w = config.image_size\n",
    "            image = torch.zeros((c, h, w))\n",
    "\n",
    "        text_inputs = self.tokenizer(\n",
    "            caption, padding='max_length', truncation=True,\n",
    "            max_length=self.max_length, return_tensors='pt'\n",
    "        )\n",
    "        input_ids = text_inputs['input_ids'].squeeze(0)\n",
    "        attention_mask = text_inputs['attention_mask'].squeeze(0)\n",
    "\n",
    "        if input_ids.dim() == 0: input_ids = input_ids.unsqueeze(0)\n",
    "        if attention_mask.dim() == 0: attention_mask = attention_mask.unsqueeze(0)\n",
    "\n",
    "        return {\n",
    "            \"pixel_values\": image,\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"raw_caption\": caption\n",
    "        }\n",
    "\n",
    "print(\"ImageCaptionDataset class defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BLIP-2 configuration for: Salesforce/blip2-flan-t5-xl\n",
      "Loading BLIP-2 model: Salesforce/blip2-flan-t5-xl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe984c507514519b6927d37d3179197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing Vision Model and Language Model parameters...\n",
      "  Vision model frozen.\n",
      "  Language model frozen.\n",
      "Verifying Q-Former parameters are trainable...\n",
      "  Note: Projection layers (vision_proj, text_proj) not found.\n",
      "\n",
      "Model components loaded successfully.\n",
      "  Total parameters: ~3942.45 M\n",
      "  Frozen parameters: ~3835.71 M\n",
      "  Trainable parameters: ~105.14 M\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Model Loading & Freezing\n",
    "\n",
    "model = None\n",
    "blip_config_loaded = None\n",
    "model_loaded = False\n",
    "\n",
    "try:\n",
    "    print(f\"Loading BLIP-2 configuration for: {config.blip2_model_name}\")\n",
    "    blip_config_loaded = Blip2Config.from_pretrained(config.blip2_model_name)\n",
    "\n",
    "    print(f\"Loading BLIP-2 model: {config.blip2_model_name}\")\n",
    "    model_dtype = torch.float16 if config.use_amp and config.device == torch.device('cuda') else torch.float32\n",
    "    model = Blip2Model.from_pretrained(\n",
    "        config.blip2_model_name,\n",
    "        config=blip_config_loaded,\n",
    "        torch_dtype=model_dtype\n",
    "    )\n",
    "\n",
    "    print(\"Freezing Vision Model and Language Model parameters...\")\n",
    "    frozen_params_count = 0\n",
    "    total_params = 0\n",
    "\n",
    "    if hasattr(model, 'vision_model'):\n",
    "        for param in model.vision_model.parameters():\n",
    "            param.requires_grad = False\n",
    "            frozen_params_count += param.numel()\n",
    "        print(f\"  Vision model frozen.\")\n",
    "    else:\n",
    "        print(\"  Warning: model.vision_model not found.\")\n",
    "\n",
    "    if hasattr(model, 'language_model'):\n",
    "        for param in model.language_model.parameters():\n",
    "            param.requires_grad = False\n",
    "            frozen_params_count += param.numel()\n",
    "        print(f\"  Language model frozen.\")\n",
    "    else:\n",
    "        print(\"  Warning: model.language_model not found.\")\n",
    "\n",
    "    trainable_params_count = 0\n",
    "    if hasattr(model, 'qformer'):\n",
    "        print(\"Verifying Q-Former parameters are trainable...\")\n",
    "        model.qformer.train()\n",
    "        for param in model.qformer.parameters():\n",
    "            param.requires_grad = True\n",
    "            trainable_params_count += param.numel()\n",
    "\n",
    "        proj_layers_found = 0\n",
    "        for proj_name in ['vision_proj', 'text_proj']:\n",
    "            if hasattr(model, proj_name):\n",
    "                layer = getattr(model, proj_name)\n",
    "                if layer is not None and isinstance(layer, nn.Module):\n",
    "                    print(f\"  Verifying {proj_name} parameters are trainable...\")\n",
    "                    layer.train()\n",
    "                    for param in layer.parameters():\n",
    "                        param.requires_grad = True\n",
    "                    trainable_params_count += sum(p.numel() for p in layer.parameters())\n",
    "                    proj_layers_found += 1\n",
    "\n",
    "        if proj_layers_found == 0:\n",
    "            print(\"  Note: Projection layers (vision_proj, text_proj) not found.\")\n",
    "\n",
    "        model.to(config.device)\n",
    "        model_loaded = True\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        print(\"\\nModel components loaded successfully.\")\n",
    "        print(f\"  Total parameters: ~{total_params / 1e6:.2f} M\")\n",
    "        print(f\"  Frozen parameters: ~{frozen_params_count / 1e6:.2f} M\")\n",
    "        print(f\"  Trainable parameters: ~{trainable_params_count / 1e6:.2f} M\")\n",
    "\n",
    "    else:\n",
    "        print(\"ERROR: model.qformer not found!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR loading model '{config.blip2_model_name}': {e}\")\n",
    "    traceback.print_exc()\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Tokenizer: vinai/phobert-base\n",
      "  PhoBERT Tokenizer Vocab Size: 64000\n",
      "Loading Image Processor for: Salesforce/blip2-flan-t5-xl\n",
      "\n",
      "Creating datasets...\n",
      "Loading data from: /home/researcher/huypq69/TuningModels/data/LANDMARK-IN-VIETNAM/train.json\n",
      "Loaded 19844 samples from train.json.\n",
      "Loading data from: /home/researcher/huypq69/TuningModels/data/LANDMARK-IN-VIETNAM/val.json\n",
      "Loaded 5667 samples from val.json.\n",
      "\n",
      "Creating dataloaders...\n",
      "Using 8 workers.\n",
      "Train loader created (620 batches).\n",
      "Validation loader created (178 batches).\n",
      "\n",
      "Data setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Data Setup (Tokenizer, Image Processor, Datasets, DataLoaders)\n",
    "\n",
    "tokenizer = None\n",
    "image_processor = None\n",
    "train_loader = None\n",
    "dev_loader = None\n",
    "data_setup_ok = False\n",
    "\n",
    "if model_loaded:\n",
    "    try:\n",
    "        print(f\"Loading Tokenizer: {config.text_tokenizer_name}\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(config.text_tokenizer_name)\n",
    "        print(f\"  PhoBERT Tokenizer Vocab Size: {tokenizer.vocab_size}\")\n",
    "\n",
    "        print(f\"Loading Image Processor for: {config.blip2_model_name}\")\n",
    "        image_processor = BlipImageProcessor.from_pretrained(config.blip2_model_name)\n",
    "        if hasattr(image_processor, 'size'):\n",
    "            processor_size = image_processor.size['height'] if isinstance(image_processor.size, dict) else image_processor.size\n",
    "            if processor_size != config.image_size:\n",
    "                print(f\"  Updating config.image_size from {config.image_size} to {processor_size}\")\n",
    "                config.image_size = processor_size\n",
    "\n",
    "        print(\"\\nCreating datasets...\")\n",
    "        train_json = os.path.join(config.data_path, \"train.json\")\n",
    "        dev_json = os.path.join(config.data_path, \"val.json\")\n",
    "\n",
    "        train_dataset = ImageCaptionDataset(\n",
    "            json_path=train_json, image_base_path=config.image_path,\n",
    "            tokenizer=tokenizer, image_processor=image_processor, max_length=config.max_length\n",
    "        )\n",
    "        dev_dataset = ImageCaptionDataset(\n",
    "            json_path=dev_json, image_base_path=config.image_path,\n",
    "            tokenizer=tokenizer, image_processor=image_processor, max_length=config.max_length\n",
    "        )\n",
    "\n",
    "        if not train_dataset.data: raise ValueError(\"Training data failed to load.\")\n",
    "        if not dev_dataset.data: print(\"Warning: Validation data not loaded.\")\n",
    "\n",
    "        print(\"\\nCreating dataloaders...\")\n",
    "        num_workers = min(config.num_workers, os.cpu_count() if os.cpu_count() else 1)\n",
    "        print(f\"Using {num_workers} workers.\")\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=num_workers,\n",
    "            pin_memory=True if config.device == torch.device(\"cuda\") else False, drop_last=True\n",
    "        )\n",
    "        print(f\"Train loader created ({len(train_loader)} batches).\")\n",
    "\n",
    "        if dev_dataset.data:\n",
    "            dev_loader = DataLoader(\n",
    "                dev_dataset, batch_size=config.batch_size, shuffle=False, num_workers=num_workers,\n",
    "                pin_memory=True if config.device == torch.device(\"cuda\") else False, drop_last=False\n",
    "            )\n",
    "            print(f\"Validation loader created ({len(dev_loader)} batches).\")\n",
    "\n",
    "        data_setup_ok = True\n",
    "        print(\"\\nData setup complete.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR during data setup: {e}\")\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"Skipping data setup because model failed to load.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting up optimizer and scheduler...\n",
      "Found 257 parameter tensors to optimize (~106.74 M).\n",
      "Optimizer AdamW initialized with lr=1.0e-04\n",
      "LR Scheduler ReduceLROnPlateau initialized (mode='max')\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Optimizer & Scheduler Setup\n",
    "\n",
    "optimizer = None\n",
    "lr_scheduler = None\n",
    "optimizer_setup_ok = False\n",
    "\n",
    "if model_loaded and data_setup_ok:\n",
    "    print(\"\\nSetting up optimizer and scheduler...\")\n",
    "    try:\n",
    "        trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "        param_count = sum(p.numel() for p in trainable_params)\n",
    "        print(f\"Found {len(trainable_params)} parameter tensors to optimize (~{param_count / 1e6:.2f} M).\")\n",
    "\n",
    "        if not trainable_params:\n",
    "            raise ValueError(\"No trainable parameters found.\")\n",
    "\n",
    "        optimizer = optim.AdamW(trainable_params, lr=config.qformer_lr, weight_decay=config.weight_decay)\n",
    "        print(f\"Optimizer AdamW initialized with lr={config.qformer_lr:.1e}\")\n",
    "\n",
    "        lr_scheduler = ReduceLROnPlateau(\n",
    "            optimizer, mode=config.mode, factor=config.factor, patience=config.patience, verbose=True\n",
    "        )\n",
    "        print(f\"LR Scheduler ReduceLROnPlateau initialized (mode='{config.mode}')\")\n",
    "        optimizer_setup_ok = True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR setting up optimizer/scheduler: {e}\")\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"Skipping optimizer setup due to previous errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss functions defined: ITC and ITM implemented, ITG is placeholder.\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Loss Function Definitions\n",
    "\n",
    "def calculate_itc_loss(image_feats_norm, text_feats_norm, temperature):\n",
    "    logits = (image_feats_norm @ text_feats_norm.T) / temperature\n",
    "    logits = logits.float()\n",
    "    batch_size = image_feats_norm.shape[0]\n",
    "    if batch_size == 0: return torch.tensor(0.0, device=logits.device)\n",
    "    labels = torch.arange(batch_size, device=logits.device)\n",
    "    loss_i = F.cross_entropy(logits, labels)\n",
    "    loss_t = F.cross_entropy(logits.T, labels)\n",
    "    return (loss_i + loss_t) / 2.0\n",
    "\n",
    "def calculate_itm_loss(model, outputs, batch_size, device):\n",
    "    \"\"\"Image-Text Matching Loss with Hard Negative Mining\"\"\"\n",
    "    if batch_size == 0 or not hasattr(model, 'qformer') or not hasattr(outputs, 'qformer_outputs'):\n",
    "        return torch.tensor(0.0, device=device)\n",
    "\n",
    "    try:\n",
    "        # Extract Q-Former multimodal features (CLS token)\n",
    "        multimodal_feats = outputs.qformer_outputs.last_hidden_state[:, 0]  # [batch_size, hidden_size]\n",
    "\n",
    "        # Hard negative mining: Find mismatched pairs with high ITC similarity\n",
    "        image_feats = model.vision_proj(outputs.image_embeds) if hasattr(model, 'vision_proj') else outputs.image_embeds\n",
    "        text_feats = model.text_proj(outputs.text_embeds) if hasattr(model, 'text_proj') else outputs.text_embeds\n",
    "        image_feats_norm = F.normalize(image_feats, dim=-1)\n",
    "        text_feats_norm = F.normalize(text_feats, dim=-1)\n",
    "        sim_matrix = image_feats_norm @ text_feats_norm.T\n",
    "        sim_matrix.fill_diagonal_(-float('inf'))  # Exclude true pairs\n",
    "        hard_neg_indices = torch.argmax(sim_matrix, dim=1)  # [batch_size]\n",
    "\n",
    "        # Create negative pairs by pairing images with hard-negative texts\n",
    "        neg_input_ids = outputs.input_ids[hard_neg_indices]\n",
    "        neg_attention_mask = outputs.attention_mask[hard_neg_indices]\n",
    "        pixel_values = outputs.pixel_values\n",
    "\n",
    "        with torch.no_grad():\n",
    "            neg_outputs = model(\n",
    "                pixel_values=pixel_values,\n",
    "                input_ids=neg_input_ids,\n",
    "                attention_mask=neg_attention_mask\n",
    "            )\n",
    "        neg_multimodal_feats = neg_outputs.qformer_outputs.last_hidden_state[:, 0]\n",
    "\n",
    "        # Combine positive and negative features\n",
    "        all_feats = torch.cat([multimodal_feats, neg_multimodal_feats], dim=0)  # [2*batch_size, hidden_size]\n",
    "        itm_logits = model.itm_head(all_feats) if hasattr(model, 'itm_head') else nn.Linear(all_feats.size(-1), 2).to(device)(all_feats)\n",
    "\n",
    "        # Labels: 1 for positive pairs, 0 for negative pairs\n",
    "        itm_labels = torch.cat([torch.ones(batch_size, dtype=torch.long), torch.zeros(batch_size, dtype=torch.long)]).to(device)\n",
    "\n",
    "        return F.cross_entropy(itm_logits, itm_labels)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in ITM loss calculation: {e}\")\n",
    "        return torch.tensor(0.0, device=device)\n",
    "\n",
    "def calculate_itg_loss(model_outputs, target_ids, target_mask):\n",
    "    return torch.tensor(0.0, device=target_ids.device)\n",
    "\n",
    "print(\"Loss functions defined: ITC and ITM implemented, ITG is placeholder.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============== Starting Q-Former Training ===============\n",
      "Epochs: 1, Batch Size: 32, Device: cuda, AMP: True\n",
      "Tracking metric: 'val_itc_acc' (mode: max)\n",
      "Early Stopping Patience: 3 epochs\n",
      "\n",
      "--- Epoch 1/1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47227/1633882599.py:15: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=config.use_amp)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f5d3649fcf49afa7ce7626f7361cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training E1:   0%|          | 0/620 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47227/1633882599.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=config.use_amp):\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [852,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [856,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [851,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [858,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [917,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [925,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [924,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [918,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [320,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_47227/1633882599.py\", line 42, in <module>\n",
      "    outputs = model(\n",
      "              ^^^^^^\n",
      "  File \"/home/researcher/huypq69/TuningModels/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/researcher/huypq69/TuningModels/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/researcher/huypq69/TuningModels/.venv/lib/python3.12/site-packages/transformers/models/blip_2/modeling_blip_2.py\", line 1736, in forward\n",
      "    inputs_embeds = self.language_model.get_input_embeddings()(input_ids)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/researcher/huypq69/TuningModels/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/researcher/huypq69/TuningModels/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/researcher/huypq69/TuningModels/.venv/lib/python3.12/site-packages/torch/nn/modules/sparse.py\", line 190, in forward\n",
      "    return F.embedding(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/researcher/huypq69/TuningModels/.venv/lib/python3.12/site-packages/torch/nn/functional.py\", line 2551, in embedding\n",
      "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at step 0: CUDA error: device-side assert triggered\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(progress_bar):\n\u001b[32m     29\u001b[39m     optimizer.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     pixel_values = \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpixel_values\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     input_ids = batch[\u001b[33m'\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m'\u001b[39m].to(config.device)\n\u001b[32m     33\u001b[39m     attention_mask = batch[\u001b[33m'\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m'\u001b[39m].to(config.device)\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Training Loop - Updated with Early Stopping\n",
    "\n",
    "ready_to_train = model_loaded and optimizer_setup_ok and data_setup_ok and train_loader is not None\n",
    "\n",
    "if ready_to_train:\n",
    "    print(f\"\\n=============== Starting Q-Former Training ===============\")\n",
    "    print(f\"Epochs: {config.epochs}, Batch Size: {config.batch_size}, Device: {config.device}, AMP: {config.use_amp}\")\n",
    "    print(f\"Tracking metric: '{config.metric_to_track}' (mode: {config.mode})\")\n",
    "    print(f\"Early Stopping Patience: {config.early_stop_patience} epochs\")\n",
    "\n",
    "    best_val_metric = -float('inf') if config.mode == \"max\" else float('inf')\n",
    "    early_stop_counter = 0\n",
    "    history = {'train_loss': [], 'train_itc_loss': [], 'train_itm_loss': [], 'validation_results': []}\n",
    "    start_train_time = time.time()\n",
    "    scaler = GradScaler(enabled=config.use_amp)\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        print(f\"\\n--- Epoch {epoch+1}/{config.epochs} ---\")\n",
    "\n",
    "        model.train()\n",
    "        train_loss_meter = AvgMeter(f\"Train Total E{epoch+1}\")\n",
    "        train_itc_meter = AvgMeter(f\"Train ITC E{epoch+1}\")\n",
    "        train_itm_meter = AvgMeter(f\"Train ITM E{epoch+1}\")\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Training E{epoch+1}\", leave=True, unit=\"batch\")\n",
    "\n",
    "        for step, batch in enumerate(progress_bar):\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            pixel_values = batch['pixel_values'].to(config.device)\n",
    "            input_ids = batch['input_ids'].to(config.device)\n",
    "            attention_mask = batch['attention_mask'].to(config.device)\n",
    "            batch_size = pixel_values.size(0)\n",
    "            if batch_size == 0: continue\n",
    "\n",
    "            expected_dtype = torch.float16 if config.use_amp else torch.float32\n",
    "            pixel_values = pixel_values.to(dtype=expected_dtype)\n",
    "\n",
    "            with autocast(enabled=config.use_amp):\n",
    "                try:\n",
    "                    outputs = model(\n",
    "                        pixel_values=pixel_values,\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        return_dict=True\n",
    "                    )\n",
    "\n",
    "                    image_embeds = outputs.image_embeds\n",
    "                    text_embeds = outputs.text_embeds\n",
    "\n",
    "                    image_feats = model.vision_proj(image_embeds) if hasattr(model, 'vision_proj') else image_embeds\n",
    "                    text_feats = model.text_proj(text_embeds) if hasattr(model, 'text_proj') else text_embeds\n",
    "\n",
    "                    image_feats_norm = F.normalize(image_feats, dim=-1)\n",
    "                    text_feats_norm = F.normalize(text_feats, dim=-1)\n",
    "\n",
    "                    loss_itc = calculate_itc_loss(image_feats_norm, text_feats_norm, config.temperature)\n",
    "                    loss_itm = calculate_itm_loss(model, outputs, batch_size, config.device)\n",
    "                    loss_itg = torch.tensor(0.0, device=config.device)\n",
    "\n",
    "                    total_loss = loss_itc + loss_itm + loss_itg\n",
    "\n",
    "                except Exception as forward_err:\n",
    "                    print(f\"Error at step {step}: {forward_err}\")\n",
    "                    traceback.print_exc()\n",
    "                    continue\n",
    "\n",
    "            if torch.isnan(total_loss) or torch.isinf(total_loss):\n",
    "                print(f\"Warning: NaN/Inf loss at step {step}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            scaler.scale(total_loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss_meter.update(total_loss.item(), batch_size)\n",
    "            train_itc_meter.update(loss_itc.item(), batch_size)\n",
    "            train_itm_meter.update(loss_itm.item(), batch_size)\n",
    "            progress_bar.set_postfix(loss=f\"{train_loss_meter.avg:.4f}\", itc=f\"{train_itc_meter.avg:.4f}\", itm=f\"{train_itm_meter.avg:.4f}\")\n",
    "\n",
    "        history['train_loss'].append(train_loss_meter.avg)\n",
    "        history['train_itc_loss'].append(train_itc_meter.avg)\n",
    "        history['train_itm_loss'].append(train_itm_meter.avg)\n",
    "        print(f\"Epoch {epoch+1}: Train Loss={train_loss_meter.avg:.4f} (ITC={train_itc_meter.avg:.4f}, ITM={train_itm_meter.avg:.4f})\")\n",
    "\n",
    "        val_results = None\n",
    "        current_val_metric = -float('inf') if config.mode == \"max\" else float('inf')\n",
    "\n",
    "        if dev_loader:\n",
    "            val_results = validate_qformer_epoch(model, dev_loader, config.device, epoch+1)\n",
    "            history['validation_results'].append(val_results)\n",
    "            current_val_metric = val_results.get(config.metric_to_track, current_val_metric)\n",
    "\n",
    "            try:\n",
    "                metric_for_scheduler = val_results.get(config.metric_to_track, val_results.get('loss', float('inf')))\n",
    "                lr_scheduler.step(metric_for_scheduler)\n",
    "                current_lrs = [group['lr'] for group in optimizer.param_groups]\n",
    "                print(f\"  Validation Metrics: {val_results}\")\n",
    "                print(f\"  Current LR(s): {[f'{lr:.2e}' for lr in current_lrs]}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error stepping scheduler: {e}\")\n",
    "        else:\n",
    "            history['validation_results'].append(None)\n",
    "\n",
    "        is_best = False\n",
    "        if dev_loader:\n",
    "            if config.mode == \"max\" and current_val_metric > best_val_metric:\n",
    "                is_best = True\n",
    "                early_stop_counter = 0  # Reset counter on improvement\n",
    "            elif config.mode == \"min\" and current_val_metric < best_val_metric:\n",
    "                is_best = True\n",
    "                early_stop_counter = 0\n",
    "            else:\n",
    "                early_stop_counter += 1\n",
    "                print(f\"  No improvement in {config.metric_to_track}. Early stop counter: {early_stop_counter}/{config.early_stop_patience}\")\n",
    "            if is_best:\n",
    "                best_val_metric = current_val_metric\n",
    "\n",
    "        model.cpu()\n",
    "        save_dict = {\n",
    "            'epoch': epoch + 1, 'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(), 'scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "            'train_loss': train_loss_meter.avg, 'validation_results': val_results,\n",
    "            'best_val_metric': best_val_metric, 'metric_tracked': config.metric_to_track,\n",
    "            'config_blip2_model_name': config.blip2_model_name, 'config_text_tokenizer_name': config.text_tokenizer_name\n",
    "        }\n",
    "        model.to(config.device)\n",
    "\n",
    "        try:\n",
    "            if config.save_best_only and dev_loader:\n",
    "                if is_best:\n",
    "                    best_ckpt_path = os.path.join(config.model_path, \"ViBLIP_QFormer_best.pt\")\n",
    "                    torch.save(save_dict, best_ckpt_path)\n",
    "                    print(f\"  Saved Best Model (Epoch {epoch+1}, {config.metric_to_track}={current_val_metric:.4f})\")\n",
    "            else:\n",
    "                epoch_ckpt_path = os.path.join(config.model_path, f\"ViBLIP_QFormer_epoch_{epoch+1}.pt\")\n",
    "                torch.save(save_dict, epoch_ckpt_path)\n",
    "                print(f\"  Saved Epoch {epoch+1} Checkpoint\")\n",
    "                if is_best and dev_loader:\n",
    "                    best_ckpt_path = os.path.join(config.model_path, \"ViBLIP_QFormer_best.pt\")\n",
    "                    torch.save(save_dict, best_ckpt_path)\n",
    "                    print(f\"  (Also marked as best model)\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR saving checkpoint for epoch {epoch+1}: {e}\")\n",
    "\n",
    "        epoch_end_time = time.time()\n",
    "        print(f\"--- Epoch {epoch+1} Time: {epoch_end_time - epoch_start_time:.2f} seconds ---\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if dev_loader and early_stop_counter >= config.early_stop_patience:\n",
    "            print(f\"\\nEarly stopping triggered after {early_stop_counter} epochs without improvement in {config.metric_to_track}.\")\n",
    "            break\n",
    "\n",
    "    end_train_time = time.time()\n",
    "    print(f\"\\n=============== Q-Former Training Finished ===============\")\n",
    "    print(f\"Total Training Time: {(end_train_time - start_train_time)/60:.2f} minutes\")\n",
    "\n",
    "    try:\n",
    "        final_model_path = os.path.join(config.model_path, 'ViBLIP_QFormer_final_epoch.pt')\n",
    "        model.cpu()\n",
    "        final_save_dict = {\n",
    "            'epoch': epoch + 1, 'model_state_dict': model.state_dict(),\n",
    "            'best_val_metric': best_val_metric, 'metric_tracked': config.metric_to_track\n",
    "        }\n",
    "        torch.save(final_save_dict, final_model_path)\n",
    "        print(f\"Final epoch model state saved to {final_model_path}\")\n",
    "        best_ckpt_path = os.path.join(config.model_path, \"ViBLIP_QFormer_best.pt\")\n",
    "        if os.path.exists(best_ckpt_path):\n",
    "            print(f\"Best model saved to: {best_ckpt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR saving final model state: {e}\")\n",
    "    print(f\"========================================================\")\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: Prerequisites not met. Training loop skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation function implemented.\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Validation Loop Implementation\n",
    "\n",
    "def validate_qformer_epoch(model, dataloader, device, epoch_num):\n",
    "    print(f\"--- Running Validation Epoch {epoch_num} ---\")\n",
    "    model.eval()\n",
    "    val_loss_meter = AvgMeter(f\"Val Total E{epoch_num}\")\n",
    "    val_itc_meter = AvgMeter(f\"Val ITC E{epoch_num}\")\n",
    "    val_itm_meter = AvgMeter(f\"Val ITM E{epoch_num}\")\n",
    "    val_itc_acc_meter = AvgMeter(f\"Val ITC Acc E{epoch_num}\")\n",
    "    val_itm_acc_meter = AvgMeter(f\"Val ITM Acc E{epoch_num}\")\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Validating E{epoch_num}\", leave=True, unit=\"batch\")\n",
    "\n",
    "    all_image_feats = []\n",
    "    all_text_feats = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            pixel_values = batch['pixel_values'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            batch_size = pixel_values.size(0)\n",
    "            if batch_size == 0: continue\n",
    "\n",
    "            expected_dtype = torch.float16 if config.use_amp else torch.float32\n",
    "            pixel_values = pixel_values.to(dtype=expected_dtype)\n",
    "\n",
    "            with autocast(enabled=config.use_amp):\n",
    "                try:\n",
    "                    outputs = model(\n",
    "                        pixel_values=pixel_values,\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        return_dict=True\n",
    "                    )\n",
    "\n",
    "                    image_embeds = outputs.image_embeds\n",
    "                    text_embeds = outputs.text_embeds\n",
    "\n",
    "                    image_feats = model.vision_proj(image_embeds) if hasattr(model, 'vision_proj') else image_embeds\n",
    "                    text_feats = model.text_proj(text_embeds) if hasattr(model, 'text_proj') else text_embeds\n",
    "\n",
    "                    image_feats_norm = F.normalize(image_feats, dim=-1)\n",
    "                    text_feats_norm = F.normalize(text_feats, dim=-1)\n",
    "\n",
    "                    loss_itc = calculate_itc_loss(image_feats_norm, text_feats_norm, config.temperature)\n",
    "                    loss_itm = calculate_itm_loss(model, outputs, batch_size, device)\n",
    "                    total_loss = loss_itc + loss_itm\n",
    "\n",
    "                    all_image_feats.append(image_feats_norm)\n",
    "                    all_text_feats.append(text_feats_norm)\n",
    "\n",
    "                    metrics = compute_metrics(image_feats_norm, text_feats_norm)\n",
    "                    itc_acc = metrics['avg_acc']\n",
    "\n",
    "                    multimodal_feats = outputs.qformer_outputs.last_hidden_state[:, 0]\n",
    "                    itm_logits = model.itm_head(multimodal_feats) if hasattr(model, 'itm_head') else nn.Linear(multimodal_feats.size(-1), 2).to(device)(multimodal_feats)\n",
    "                    itm_preds = torch.argmax(itm_logits, dim=-1)\n",
    "                    itm_labels = torch.ones(batch_size, dtype=torch.long).to(device)\n",
    "                    itm_acc = (itm_preds == itm_labels).float().mean().item()\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in validation batch: {e}\")\n",
    "                    continue\n",
    "\n",
    "                val_loss_meter.update(total_loss.item(), batch_size)\n",
    "                val_itc_meter.update(loss_itc.item(), batch_size)\n",
    "                val_itm_meter.update(loss_itm.item(), batch_size)\n",
    "                val_itc_acc_meter.update(itc_acc, batch_size)\n",
    "                val_itm_acc_meter.update(itm_acc, batch_size)\n",
    "\n",
    "                progress_bar.set_postfix(loss=f\"{val_loss_meter.avg:.4f}\", itc_acc=f\"{val_itc_acc_meter.avg:.4f}\", itm_acc=f\"{val_itm_acc_meter.avg:.4f}\")\n",
    "\n",
    "    all_image_feats = torch.cat(all_image_feats, dim=0)\n",
    "    all_text_feats = torch.cat(all_text_feats, dim=0)\n",
    "    final_metrics = compute_metrics(all_image_feats, all_text_feats)\n",
    "\n",
    "    results = {\n",
    "        'loss': val_loss_meter.avg,\n",
    "        'val_itc_acc': val_itc_acc_meter.avg,\n",
    "        'val_itm_acc': val_itm_acc_meter.avg,\n",
    "        'val_itc_loss': val_itc_meter.avg,\n",
    "        'val_itm_loss': val_itm_meter.avg,\n",
    "        'i2t_recall': final_metrics['i2t_recall'],\n",
    "        't2i_recall': final_metrics['t2i_recall']\n",
    "    }\n",
    "\n",
    "    print(f\"Validation Epoch {epoch_num} Results: Loss={results['loss']:.4f}, ITC Acc={results['val_itc_acc']:.4f}, ITM Acc={results['val_itm_acc']:.4f}\")\n",
    "    print(f\"  I2T Recall: {results['i2t_recall']}\")\n",
    "    print(f\"  T2I Recall: {results['t2i_recall']}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "print(\"Validation function implemented.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============== Starting Test Set Evaluation ===============\n",
      "Skipping test evaluation: Model or data setup failed.\n",
      "Test set evaluation was not performed.\n",
      "\n",
      "================= Evaluation Finished =================\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Test Set Evaluation\n",
    "\n",
    "print(\"\\n=============== Starting Test Set Evaluation ===============\")\n",
    "\n",
    "test_json_path = os.path.join(config.data_path, \"test.json\")\n",
    "evaluation_performed = False\n",
    "model_loaded_for_test = False\n",
    "\n",
    "if not (model_loaded and data_setup_ok):\n",
    "    print(\"Skipping test evaluation: Model or data setup failed.\")\n",
    "elif not os.path.exists(test_json_path):\n",
    "    print(f\"Skipping test evaluation: Test JSON not found ({test_json_path}).\")\n",
    "else:\n",
    "    print(f\"Loading test data from: {test_json_path}\")\n",
    "    if 'tokenizer' in globals() and 'image_processor' in globals():\n",
    "        test_dataset = ImageCaptionDataset(\n",
    "            json_path=test_json_path, image_base_path=config.image_path,\n",
    "            tokenizer=tokenizer, image_processor=image_processor, max_length=config.max_length\n",
    "        )\n",
    "\n",
    "        if test_dataset.data:\n",
    "            num_workers = min(config.num_workers, os.cpu_count() if os.cpu_count() else 1)\n",
    "            test_loader = DataLoader(\n",
    "                test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=num_workers,\n",
    "                pin_memory=True if config.device == torch.device(\"cuda\") else False, drop_last=False\n",
    "            )\n",
    "            print(f\"Test loader created with {len(test_loader)} batches.\")\n",
    "\n",
    "            model_to_test = None\n",
    "            try:\n",
    "                blip_config_test = Blip2Config.from_pretrained(config.blip2_model_name)\n",
    "                model_to_test = Blip2Model.from_pretrained(\n",
    "                    config.blip2_model_name, config=blip_config_test,\n",
    "                    torch_dtype=torch.float16 if config.use_amp else torch.float32\n",
    "                )\n",
    "                for param in model_to_test.vision_model.parameters(): param.requires_grad = False\n",
    "                if hasattr(model_to_test, 'language_model'):\n",
    "                    for param in model_to_test.language_model.parameters(): param.requires_grad = False\n",
    "                print(\"Model structure for testing created.\")\n",
    "\n",
    "                best_model_path = os.path.join(config.model_path, \"ViBLIP_QFormer_best.pt\")\n",
    "                if os.path.exists(best_model_path):\n",
    "                    print(f\"Loading best model weights from: {best_model_path}\")\n",
    "                    checkpoint = torch.load(best_model_path, map_location='cpu')\n",
    "                    state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "                    if next(iter(state_dict)).startswith('module.'):\n",
    "                        from collections import OrderedDict\n",
    "                        state_dict = OrderedDict((k[7:], v) for k, v in state_dict.items())\n",
    "\n",
    "                    load_result = model_to_test.load_state_dict(state_dict, strict=False)\n",
    "                    print(f\"Load Result: {load_result}\")\n",
    "                    model_to_test.to(config.device)\n",
    "                    model_loaded_for_test = True\n",
    "                    print(\"Loaded trained weights into model structure.\")\n",
    "\n",
    "                    print(\"\\nRunning evaluation on test set...\")\n",
    "                    test_results = validate_qformer_epoch(model_to_test, test_loader, config.device, \"Test\")\n",
    "                    evaluation_performed = True\n",
    "                    print(\"\\n--- Test Set Results ---\")\n",
    "                    metric_log_str = f\"  Loss: {test_results['loss']:.4f}\\n\"\n",
    "                    metric_log_str += f\"  ITC Acc: {test_results['val_itc_acc']:.4f}\\n\"\n",
    "                    metric_log_str += f\"  ITM Acc: {test_results['val_itm_acc']:.4f}\\n\"\n",
    "                    metric_log_str += f\"  I2T Recall: {test_results['i2t_recall']}\\n\"\n",
    "                    metric_log_str += f\"  T2I Recall: {test_results['t2i_recall']}\\n\"\n",
    "                    print(metric_log_str.strip())\n",
    "                    print(\"------------------------\")\n",
    "\n",
    "                else:\n",
    "                    print(f\"ERROR: Best model checkpoint not found at {best_model_path}.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR during test setup or evaluation: {e}\")\n",
    "                traceback.print_exc()\n",
    "        else:\n",
    "            print(\"Could not load test data. Skipping test evaluation.\")\n",
    "    else:\n",
    "        print(\"Skipping test evaluation: Tokenizer or Image Processor not available.\")\n",
    "\n",
    "if not evaluation_performed:\n",
    "    print(\"Test set evaluation was not performed.\")\n",
    "\n",
    "print(\"\\n================= Evaluation Finished =================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
